{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067be436-38be-499b-afd9-1e004ac7a665",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING = 0\n",
    "CRACK = 1\n",
    "LCD = 2\n",
    "\n",
    "CLASS_NUMBERS = [WORKING, CRACK, LCD]\n",
    "CLASS_NAMES = [\"Working\", \"Crack\", \"LCD\"]\n",
    "\n",
    "NUM_CLASSES = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11486602-e42f-4b3c-b735-da7cfa4085db",
   "metadata": {},
   "source": [
    "# Creating dummy data\n",
    "\n",
    "Only run this section if you want to test stuff quickly without dealing with the real dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bf19c2-f476-4d26-8178-5ba5358a8110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "X = rng.integers(low = 0, high = 256, size = (100, 400, 300, 3))\n",
    "y = rng.integers(low = 0, high = NUM_CLASSES, size = 100).reshape((100, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2b8ab8-d7d8-4220-b10a-5d7facd33d64",
   "metadata": {},
   "source": [
    "# Reading data from files\n",
    "\n",
    "Don't run this section if you want to work with dummy data, it will overwrite variables `X` and `y` from previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efabe1c2-6e34-4239-acff-158e03156c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def collect_file_paths(path: str, ext: str) -> list[str]:\n",
    "    result = []\n",
    "    \n",
    "    for item in os.listdir(path):\n",
    "        item_path = os.path.join(path, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            result.extend(collect_file_paths(item_path, ext))\n",
    "        elif item_path.endswith(ext):\n",
    "            result.append(item_path)\n",
    "                \n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cee07c-dcf1-4a7b-ab45-393a0fa77a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def images_to_array(image_paths: list[str], shrink_factor: int) -> np.ndarray:\n",
    "    images = []\n",
    "    \n",
    "    for image_file in image_paths:\n",
    "        image = cv2.cvtColor(cv2.imread(image_file), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        new_size = (\n",
    "            image.shape[1] // shrink_factor, \n",
    "            image.shape[0] // shrink_factor\n",
    "        )\n",
    "        image = cv2.resize(image, dsize = new_size, interpolation = cv2.INTER_AREA)\n",
    "        images.append(image)\n",
    "        \n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec74d02-bb8f-4ea8-aeca-5b10129f2d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = collect_file_paths(\"images_for_model\", \".jpeg\")\n",
    "\n",
    "input_filepaths = []\n",
    "labels_list = []\n",
    "\n",
    "for path in file_paths:\n",
    "    file_name = path.split(\"/\")[-1]\n",
    "    labels = file_name.split(\"_\")\n",
    "    \n",
    "    if not (\"unknown\" in labels):\n",
    "        if \"crack\" in labels:\n",
    "            labels_list.append(CRACK)\n",
    "        elif \"lcd\" in labels:\n",
    "            labels_list.append(LCD)\n",
    "        else:\n",
    "            labels_list.append(WORKING)\n",
    "\n",
    "        input_filepaths.append(path)\n",
    "        \n",
    "X = images_to_array(input_filepaths, 20)\n",
    "y = np.array(labels_list).reshape((len(labels_list), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ef85f8-6fb3-4dc8-bbad-6f989590a619",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2f7f64-4325-4b7a-ab1a-2cd179dae55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = X.shape[0]\n",
    "IMAGE_WIDTH = X.shape[1]\n",
    "IMAGE_HEIGHT = X.shape[2]\n",
    "IMAGE_SHAPE = (X.shape[1], X.shape[2], X.shape[3])\n",
    "\n",
    "print(\"Entire dataset\")\n",
    "print(\"--------------\")\n",
    "print(\"Input shape: \", X.shape)\n",
    "print(\"Output shape: \", y.shape)\n",
    "print(\"Number of working phones: \", np.sum(y == WORKING))\n",
    "print(\"Number of cracked phones: \", np.sum(y == CRACK))\n",
    "print(\"Number of phones with damaged lcd: \", np.sum(y == LCD))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89ba731-b546-48c7-b249-9dcb20a5bd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "idx_working = np.where(y == WORKING)[0][:3]\n",
    "idx_cracked = np.where(y == CRACK)[0][:3]\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(12, 12))\n",
    "\n",
    "for i in range(3):\n",
    "    axs[0, i].set_title(\"Working\")\n",
    "    axs[0, i].imshow(X[idx_working[i]])\n",
    "\n",
    "    axs[1, i].set_title(\"Cracked\")\n",
    "    axs[1, i].imshow(X[idx_cracked[i]])\n",
    "\n",
    "plt.setp(axs, xticks=[], yticks=[]) # set all axes off\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b852d6-e9c1-49ea-a568-d2b0d52590b2",
   "metadata": {},
   "source": [
    "# Defining the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe1b04e-19d4-48c7-89ce-fbb14bb8075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, Model, regularizers, optimizers, Sequential\n",
    "from keras.layers import Conv2D, Activation, Flatten, Dense, MaxPooling2D, BatchNormalization, Dropout\n",
    "\n",
    "# This Convolutional neural network architecture is taken from\n",
    "# Zeiler et al., Visualizing and Understanding Convolutional Networks (2013)\n",
    "def define_model(learning_rate = 0.001):\n",
    "    inputs = Input(shape = IMAGE_SHAPE)\n",
    "    \n",
    "    hidden = Conv2D(\n",
    "        filters = 96, \n",
    "        kernel_size = (7, 7), \n",
    "        strides = (2, 2),\n",
    "        activation = \"relu\"\n",
    "    )(inputs)\n",
    "    \n",
    "    hidden = MaxPooling2D(\n",
    "        pool_size = (3, 3), \n",
    "        strides = (2, 2)\n",
    "    )(hidden)\n",
    "    \n",
    "    # Instance (or Contrast) Normalization\n",
    "    # https://medium.com/techspace-usict/normalization-techniques-in-deep-neural-networks-9121bf100d8\n",
    "    # https://stackoverflow.com/questions/68088889/how-to-add-instancenormalization-on-tensorflow-keras\n",
    "    hidden = BatchNormalization(\n",
    "        axis = 3\n",
    "    )(hidden, training = True)\n",
    "\n",
    "    hidden = Conv2D(\n",
    "        filters = 256, \n",
    "        kernel_size = (5, 5), \n",
    "        strides = (2, 2),\n",
    "        activation = \"relu\"\n",
    "    )(hidden)\n",
    "\n",
    "    hidden = MaxPooling2D(\n",
    "        pool_size = (3, 3), \n",
    "        strides = (2, 2)\n",
    "    )(hidden)\n",
    "    \n",
    "    hidden = BatchNormalization(\n",
    "        axis = 3\n",
    "    )(hidden, training = True)\n",
    "  \n",
    "    hidden = Conv2D(\n",
    "        filters = 384, \n",
    "        kernel_size = (3, 3), \n",
    "        strides = (1, 1),\n",
    "        padding = \"same\",\n",
    "        activation = \"relu\"\n",
    "    )(hidden)\n",
    "    \n",
    "    hidden = Conv2D(\n",
    "        filters = 384, \n",
    "        kernel_size = (3, 3), \n",
    "        strides = (1, 1),\n",
    "        padding = \"same\",\n",
    "        activation = \"relu\"\n",
    "    )(hidden)\n",
    "    \n",
    "    hidden = Conv2D(\n",
    "        filters = 256, \n",
    "        kernel_size = (3, 3), \n",
    "        strides = (1, 1),\n",
    "        padding = \"same\",\n",
    "        activation = \"relu\"\n",
    "    )(hidden)\n",
    "    \n",
    "    hidden = MaxPooling2D(\n",
    "        pool_size = (3, 3), \n",
    "        strides = (2, 2)\n",
    "    )(hidden)\n",
    "    \n",
    "    hidden = BatchNormalization(\n",
    "        axis = 3\n",
    "    )(hidden, training = True)\n",
    "    \n",
    "    hidden = Flatten()(hidden)\n",
    "    \n",
    "    hidden = Dense(4096, activation='relu')(hidden)\n",
    "    hidden = Dropout(0.5)(hidden)\n",
    "    hidden = Dense(4096, activation='relu')(hidden)\n",
    "    hidden = Dropout(0.5)(hidden)\n",
    "    outputs = Dense(NUM_CLASSES, activation='softmax')(hidden)\n",
    "    \n",
    "    model = Model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "    model.compile(\n",
    "        loss = 'sparse_categorical_crossentropy', \n",
    "        optimizer = optimizers.Adam(learning_rate = learning_rate), \n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3063622c-cbdd-4779-aba4-8f40825b5fde",
   "metadata": {},
   "source": [
    "# Utility function to plot training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d795fb01-1125-4f7c-b00b-1b6639409b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_curves(history):\n",
    "    plt.figure(figsize=(16, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Accuracy')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156c93ed-9f8a-48d2-bedb-5da770728d95",
   "metadata": {},
   "source": [
    "# Training the model and plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a82027e-a24b-465f-8cc3-bd6f14b8dee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "K = 5\n",
    "kFold = StratifiedKFold(n_splits = K, shuffle = True)\n",
    "\n",
    "confusion_matrices = []\n",
    "mean_acc = 0\n",
    "mean_loss = 0\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kFold.split(X, y)):\n",
    "    print(\"Running Fold\", i + 1, \"/\", K)\n",
    "    print(\"----------------\")\n",
    "    model = define_model()\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    history = model.fit(\n",
    "        x = X_train, y = y_train, \n",
    "        validation_data = (X_test, y_test), \n",
    "        batch_size = 64, epochs = 7\n",
    "    )\n",
    "    \n",
    "    mean_acc += np.max(history.history['val_accuracy'])\n",
    "    mean_loss += np.min(history.history['val_loss'])\n",
    "    \n",
    "    y_true = y_test.flatten()\n",
    "    # TODO: model.predict should use weights from the best epoch\n",
    "    y_pred = np.argmax(model.predict(X_test), axis = 1)\n",
    "    \n",
    "    confusion_matrices.append(\n",
    "        confusion_matrix(y_true, y_pred, labels = CLASS_NUMBERS)\n",
    "    )\n",
    "\n",
    "mean_acc /= K\n",
    "mean_loss /= K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984ab16b-5654-4e8b-ae22-e731e86c311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average accuracy: \", np.round(mean_acc, 3))\n",
    "print(\"Average loss: \", np.round(mean_loss, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f603afa-b4b4-413e-8b2c-eddd08185115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(K):\n",
    "    print(\"Confusion matrix of fold\", i + 1, \"/\", K)\n",
    "    \n",
    "    disp = ConfusionMatrixDisplay(\n",
    "        confusion_matrix = confusion_matrices[i], \n",
    "        display_labels = CLASS_NAMES\n",
    "    )\n",
    "    disp.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58869464-cf3f-47f3-989f-f7579c60a23d",
   "metadata": {},
   "source": [
    "# Trained the model on the entire dataset and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24830429-6258-4723-b98d-e3cde82d90d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_model()\n",
    "\n",
    "history = model.fit(\n",
    "    x = X, y = y,\n",
    "    batch_size = 64, epochs = 10\n",
    ")\n",
    "model_folder_name = \"cnn_model_acc=\" + str(np.round(acc, 3)) + \"_loss=\" + str(np.round(acc, 3))\n",
    "model.save(\"saved_models/\" + model_folder_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
